{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantiagoGomezfpv/hyperparameter/blob/main/CargarPickles_perRow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ANsQc1YfKQ"
      },
      "source": [
        "# Notebook Base para pruebas RZ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRu-tvvgYh9X",
        "outputId": "f0a65df1-483c-4537-fdcb-74e7cb088db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/JOVEN INVESTIGADOR/Data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn2LYctJZGF4",
        "outputId": "075602d5-02c3-4c6f-badd-46ba03698534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/JOVEN INVESTIGADOR/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE7oSJitYfKR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTygT8G_YfKS"
      },
      "source": [
        "## Índices Acústicos\n",
        "\n",
        "Generados con scikit-maad, basado en https://scikit-maad.github.io/_auto_examples/2_advanced/plot_extract_alpha_indices.html#sphx-glr-auto-examples-2-advanced-plot-extract-alpha-indices-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aokWXq15YfKT",
        "outputId": "0a65b2ef-2672-4b87-a50f-c8f5eadc5b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos Cargados!\n"
          ]
        }
      ],
      "source": [
        "with open('./ais_perRow.pickle', 'rb') as handle:\n",
        "    unserialized_data = pickle.load(handle)\n",
        "    X_ai = unserialized_data['X']\n",
        "    y_ai = unserialized_data['y']\n",
        "    print('Datos Cargados!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrqSlZKGYfKT",
        "outputId": "111cf59e-da33-420a-94fb-3a1d22d274d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "481"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sum(sum(np.isnan(X_ai)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdw9mloHYfKT"
      },
      "outputs": [],
      "source": [
        "X_ai[np.isnan(X_ai)] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLkmu_VQYfKT",
        "outputId": "65813371-2698-4b60-edf7-b060d58cf287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sum(sum(np.isnan(X_ai)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlWeZ1JTYfKU",
        "outputId": "4812864f-c2e4-45d4-bd9c-91de4697ae32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño matriz de características: (71497, 60)\n",
            "Tamaño vector de etiquetas: (71497, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Tamaño matriz de características: {X_ai.shape}')\n",
        "print(f'Tamaño vector de etiquetas: {y_ai.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdTgnR-mYfKU"
      },
      "source": [
        "## VGGish\n",
        "\n",
        "S. Hershey et al., ‘CNN Architectures for Large-Scale Audio Classification’,\\ in International Conference on Acoustics, Speech and Signal Processing (ICASSP),2017\\ Available: https://arxiv.org/abs/1609.09430, https://ai.google/research/pubs/pub45611\n",
        "\n",
        "Modelo preentrenado usado: https://github.com/harritaylor/torchvggish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSTq0Yn8YfKU",
        "outputId": "c7acce84-e55e-4eee-8cb2-bb70435c930f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos Cargados!\n"
          ]
        }
      ],
      "source": [
        "with open('./vgg_perRow.pickle', 'rb') as handle:\n",
        "    unserialized_data = pickle.load(handle)\n",
        "    X_vgg = unserialized_data['X']\n",
        "    y_vgg = unserialized_data['y']\n",
        "    print('Datos Cargados!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKH6_ZhzYfKU",
        "outputId": "7256cf89-7c82-4ec1-88da-150e6d716f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño matriz de características: (71497, 128)\n",
            "Tamaño vector de etiquetas: (71497, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Tamaño matriz de características: {X_vgg.shape}')\n",
        "print(f'Tamaño vector de etiquetas: {y_vgg.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0GdBE9LYfKU"
      },
      "source": [
        "## YAMNet\n",
        "\n",
        "https://www.diva-portal.org/smash/get/diva2:1605037/FULLTEXT01.pdf\n",
        "\n",
        "Modelo preentrenado usado: https://tfhub.dev/google/yamnet/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxPlLOJ6YfKV",
        "outputId": "e464b6e6-8c0f-4e70-e738-ccfc7c46eda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos Cargados!\n"
          ]
        }
      ],
      "source": [
        "with open('./yamn_perRow.pickle', 'rb') as handle:\n",
        "    unserialized_data = pickle.load(handle)\n",
        "    X_yamn = unserialized_data['X']\n",
        "    y_yamn = unserialized_data['y']\n",
        "    print('Datos Cargados!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1w7u5m6YfKV",
        "outputId": "163126bd-7404-4894-a9dc-8d56e43a2d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño matriz de características: (71497, 1024)\n",
            "Tamaño vector de etiquetas: (71497, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Tamaño matriz de características: {X_yamn.shape}')\n",
        "print(f'Tamaño vector de etiquetas: {y_yamn.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLxwm8fYYfKV"
      },
      "source": [
        "## PANNs\n",
        "\n",
        "Kong, Qiuqiang, Yin Cao, Turab Iqbal, Yuxuan Wang, Wenwu Wang, and Mark D. Plumbley. \"PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition.\" arXiv preprint arXiv:1912.10211 (2019).\n",
        "\n",
        "Modelo preentrenado usado https://github.com/qiuqiangkong/panns_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJJf8r3YfKV",
        "outputId": "80dfadc4-f1ef-4a6f-db75-7138456d8dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos Cargados!\n"
          ]
        }
      ],
      "source": [
        "with open('./panns_perRow.pickle', 'rb') as handle:\n",
        "    unserialized_data = pickle.load(handle)\n",
        "    X_panns = unserialized_data['X']\n",
        "    y_panns = unserialized_data['y']\n",
        "    print('Datos Cargados!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBG0CNCwYfKV",
        "outputId": "46b88124-da21-4945-e572-9290f3d08405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño matriz de características: (71497, 2048)\n",
            "Tamaño vector de etiquetas: (71497, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Tamaño matriz de características: {X_panns.shape}')\n",
        "print(f'Tamaño vector de etiquetas: {y_panns.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwVtBwzYfKV",
        "outputId": "16b54587-9418-4800-b979-802c928f3d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0., 1., 2.]), array([41957, 14994, 14546]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(y_vgg, return_counts=True)) # Las etiquetas son 0, 1 y 2. Hacen referencia a lo siguiente:\n",
        "NumtoCover = {0: 'Pastizal', 1:'Sabana', 2:'Bosque'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMIETXsMYfKW"
      },
      "source": [
        "## Celda para división de datos en Entrenamiento/Validación/Prueba (Train/val/test)\n",
        "\n",
        "La siguiente celda se hace con la intención de dividir el conjunto de índices acústicos (_ai) en conjuntos de entrenamiento, validación y prueba con una proporción 80%/10%/10%.\n",
        "\n",
        "Adicionalmente se almacenan los índices con los que se realizó la división, esto con el fin de realizar exactamente la misma separación con las características VGGish, PANNs y YAMNet. Lo anterior para garantizar que se están trabajando con las mismas grabaciones sin importar la caracterización.\n",
        "\n",
        "Las etiquetas son las mismas para todos los conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoyQU-qBYfKW"
      },
      "outputs": [],
      "source": [
        "n_samples = X_ai.shape[0]\n",
        "indices = np.arange(n_samples)\n",
        "\n",
        "X_ai_train, X_ai_test, y_train, y_test, idx_train, idx_test = train_test_split(X_ai, y_ai, indices, test_size=0.2)\n",
        "X_ai_val, X_ai_test, y_val, y_test, idx_val, idx_test = train_test_split(X_ai_test, y_test, idx_test, test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijLk4jPYfKW",
        "outputId": "324814b5-1ca3-4f29-abea-dd9e30e7ce5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57197, 60)\n",
            "(7150, 60)\n",
            "(7150, 60)\n"
          ]
        }
      ],
      "source": [
        "print(X_ai_train.shape)\n",
        "print(X_ai_val.shape)\n",
        "print(X_ai_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaS0uQgGYfKW",
        "outputId": "63bf1652-9baf-48d7-d647-2b2bd47d48d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57197, 1)\n",
            "(7150, 1)\n",
            "(7150, 1)\n",
            "(71497, 1)\n"
          ]
        }
      ],
      "source": [
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)\n",
        "print(y_ai.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5qKwlxHYfKW"
      },
      "source": [
        "### VGGish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epwLkV5BYfKW"
      },
      "outputs": [],
      "source": [
        "X_vgg_train = X_vgg[idx_train]\n",
        "X_vgg_val = X_vgg[idx_val]\n",
        "X_vgg_test = X_vgg[idx_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmYTMxm7YfKW",
        "outputId": "16761751-9e4c-4308-de6e-fd08df93adc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57197, 128)\n",
            "(7150, 128)\n",
            "(7150, 128)\n"
          ]
        }
      ],
      "source": [
        "print(X_vgg_train.shape)\n",
        "print(X_vgg_val.shape)\n",
        "print(X_vgg_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAe1zlM_YfKW"
      },
      "source": [
        "### YAMNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTl-tKMKYfKW"
      },
      "outputs": [],
      "source": [
        "X_yamn_train = X_yamn[idx_train]\n",
        "X_yamn_val = X_yamn[idx_val]\n",
        "X_yamn_test = X_yamn[idx_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_-CiQodYfKW",
        "outputId": "757340ae-f79e-4845-95ac-a3384139932c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57197, 1024)\n",
            "(7150, 1024)\n",
            "(7150, 1024)\n"
          ]
        }
      ],
      "source": [
        "print(X_yamn_train.shape)\n",
        "print(X_yamn_val.shape)\n",
        "print(X_yamn_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9SUIr2iYfKX"
      },
      "source": [
        "### PANNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "letSNRXsYfKX"
      },
      "outputs": [],
      "source": [
        "X_panns_train = X_panns[idx_train]\n",
        "X_panns_val = X_panns[idx_val]\n",
        "X_panns_test = X_panns[idx_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfpLCroxYfKX",
        "outputId": "360fa4cf-cdcc-4cf6-9bd4-9c36dde4ea8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57197, 2048)\n",
            "(7150, 2048)\n",
            "(7150, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(X_panns_train.shape)\n",
        "print(X_panns_val.shape)\n",
        "print(X_panns_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Técnicas tradicionales clasificadores"
      ],
      "metadata": {
        "id": "K5CKj0leLFRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna scikit-learn xgboost matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swTe8Bp4LJpL",
        "outputId": "b0ed123b-c6ac-455e-d687-4b1bbede86be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Asegúrate de que y_train, y_val y y_test sean vectores 1D\n",
        "y_train = y_train.ravel()\n",
        "y_val = y_val.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "datasets = {\n",
        "    'Acoustic Indices': (X_ai_train, y_train),\n",
        "    'VGGish': (X_vgg_train, y_train),\n",
        "    'YAMNet': (X_yamn_train, y_train),\n",
        "    'PANNs': (X_panns_train, y_train)\n",
        "}"
      ],
      "metadata": {
        "id": "PO6MSvwoLPRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forest + Optuna**"
      ],
      "metadata": {
        "id": "1xlMqQE7NEnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_rf(trial, X_train, y_train):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 16)\n",
        "\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=3)\n",
        "    return scores.mean()\n",
        "\n",
        "# Crear y optimizar estudio con Optuna para cada conjunto de datos\n",
        "best_params_rf = {}\n",
        "for dataset_name, (X_train, y_train) in datasets.items():\n",
        "    study_rf = optuna.create_study(direction='maximize')\n",
        "    study_rf.optimize(lambda trial: objective_rf(trial, X_train, y_train), n_trials=50)\n",
        "    best_params_rf[dataset_name] = study_rf.best_params\n",
        "    print(f'Best parameters for Random Forest ({dataset_name}): {study_rf.best_params}')"
      ],
      "metadata": {
        "id": "AOoVz9u3LTxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f888d9d4-5fcd-42e2-82f4-b7b9c43d184c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-11 23:06:55,107] A new study created in memory with name: no-name-b047f2a7-b4cf-4b49-9584-d1322a364c2d\n",
            "[I 2024-06-11 23:10:20,548] Trial 0 finished with value: 0.7963354931072684 and parameters: {'n_estimators': 156, 'max_depth': 23, 'min_samples_split': 9}. Best is trial 0 with value: 0.7963354931072684.\n",
            "[I 2024-06-11 23:14:15,092] Trial 1 finished with value: 0.8002868058444764 and parameters: {'n_estimators': 175, 'max_depth': 27, 'min_samples_split': 7}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:14:25,422] Trial 2 finished with value: 0.6584261000618014 and parameters: {'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 16}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:18:32,940] Trial 3 finished with value: 0.7982412027468238 and parameters: {'n_estimators': 187, 'max_depth': 31, 'min_samples_split': 9}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:20:15,045] Trial 4 finished with value: 0.781002536984016 and parameters: {'n_estimators': 82, 'max_depth': 16, 'min_samples_split': 5}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:21:34,954] Trial 5 finished with value: 0.6441246283620073 and parameters: {'n_estimators': 139, 'max_depth': 6, 'min_samples_split': 14}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:22:28,762] Trial 6 finished with value: 0.7887476932517791 and parameters: {'n_estimators': 41, 'max_depth': 21, 'min_samples_split': 6}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:23:40,011] Trial 7 finished with value: 0.6813818653983956 and parameters: {'n_estimators': 102, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:24:54,725] Trial 8 finished with value: 0.7848663295361885 and parameters: {'n_estimators': 59, 'max_depth': 22, 'min_samples_split': 15}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:25:24,323] Trial 9 finished with value: 0.6824133635772663 and parameters: {'n_estimators': 42, 'max_depth': 8, 'min_samples_split': 14}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:29:32,978] Trial 10 finished with value: 0.7944298311531418 and parameters: {'n_estimators': 192, 'max_depth': 32, 'min_samples_split': 11}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:33:50,993] Trial 11 finished with value: 0.7984684962593578 and parameters: {'n_estimators': 196, 'max_depth': 32, 'min_samples_split': 9}. Best is trial 1 with value: 0.8002868058444764.\n",
            "[I 2024-06-11 23:37:05,926] Trial 12 finished with value: 0.8006539634702289 and parameters: {'n_estimators': 149, 'max_depth': 28, 'min_samples_split': 6}. Best is trial 12 with value: 0.8006539634702289.\n",
            "[I 2024-06-11 23:40:31,320] Trial 13 finished with value: 0.8000944474105699 and parameters: {'n_estimators': 156, 'max_depth': 27, 'min_samples_split': 6}. Best is trial 12 with value: 0.8006539634702289.\n",
            "[I 2024-06-11 23:43:07,469] Trial 14 finished with value: 0.7803731425138549 and parameters: {'n_estimators': 140, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 12 with value: 0.8006539634702289.\n",
            "[I 2024-06-11 23:45:40,055] Trial 15 finished with value: 0.7987657186189049 and parameters: {'n_estimators': 117, 'max_depth': 27, 'min_samples_split': 7}. Best is trial 12 with value: 0.8006539634702289.\n",
            "[I 2024-06-11 23:49:23,033] Trial 16 finished with value: 0.8030142124494238 and parameters: {'n_estimators': 170, 'max_depth': 26, 'min_samples_split': 4}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-11 23:51:23,085] Trial 17 finished with value: 0.7491477096225537 and parameters: {'n_estimators': 121, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-11 23:51:57,831] Trial 18 finished with value: 0.6081787488658548 and parameters: {'n_estimators': 165, 'max_depth': 2, 'min_samples_split': 2}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-11 23:54:53,913] Trial 19 finished with value: 0.7954613385022871 and parameters: {'n_estimators': 141, 'max_depth': 19, 'min_samples_split': 4}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-11 23:57:04,141] Trial 20 finished with value: 0.7928213126941994 and parameters: {'n_estimators': 99, 'max_depth': 24, 'min_samples_split': 11}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-12 00:00:45,064] Trial 21 finished with value: 0.8000245479084359 and parameters: {'n_estimators': 170, 'max_depth': 27, 'min_samples_split': 7}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-12 00:04:41,770] Trial 22 finished with value: 0.800881206546252 and parameters: {'n_estimators': 177, 'max_depth': 29, 'min_samples_split': 7}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-12 00:08:41,864] Trial 23 finished with value: 0.8029967091460386 and parameters: {'n_estimators': 177, 'max_depth': 29, 'min_samples_split': 5}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-12 00:12:35,362] Trial 24 finished with value: 0.8022099335038618 and parameters: {'n_estimators': 179, 'max_depth': 24, 'min_samples_split': 4}. Best is trial 16 with value: 0.8030142124494238.\n",
            "[I 2024-06-12 00:16:57,722] Trial 25 finished with value: 0.8043079795686646 and parameters: {'n_estimators': 197, 'max_depth': 25, 'min_samples_split': 4}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:21:10,148] Trial 26 finished with value: 0.7941150972369623 and parameters: {'n_estimators': 198, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:23:57,795] Trial 27 finished with value: 0.7997447949222575 and parameters: {'n_estimators': 123, 'max_depth': 25, 'min_samples_split': 5}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:27:33,970] Trial 28 finished with value: 0.8035037336360918 and parameters: {'n_estimators': 161, 'max_depth': 30, 'min_samples_split': 3}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:30:54,411] Trial 29 finished with value: 0.7925766011618354 and parameters: {'n_estimators': 158, 'max_depth': 22, 'min_samples_split': 11}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:34:26,553] Trial 30 finished with value: 0.7998147182671057 and parameters: {'n_estimators': 161, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:38:39,569] Trial 31 finished with value: 0.8040456812834152 and parameters: {'n_estimators': 182, 'max_depth': 29, 'min_samples_split': 2}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:42:46,057] Trial 32 finished with value: 0.8042730142281306 and parameters: {'n_estimators': 183, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 25 with value: 0.8043079795686646.\n",
            "[I 2024-06-12 00:46:54,802] Trial 33 finished with value: 0.805112222750155 and parameters: {'n_estimators': 185, 'max_depth': 31, 'min_samples_split': 2}. Best is trial 33 with value: 0.805112222750155.\n",
            "[I 2024-06-12 00:51:04,856] Trial 34 finished with value: 0.8047275819956218 and parameters: {'n_estimators': 186, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 33 with value: 0.805112222750155.\n",
            "[I 2024-06-12 00:55:29,596] Trial 35 finished with value: 0.8052171123525645 and parameters: {'n_estimators': 199, 'max_depth': 31, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 00:59:55,539] Trial 36 finished with value: 0.8045177972886378 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:04:22,050] Trial 37 finished with value: 0.8045177972886378 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:08:31,103] Trial 38 finished with value: 0.803661063454569 and parameters: {'n_estimators': 187, 'max_depth': 31, 'min_samples_split': 3}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:11:50,905] Trial 39 finished with value: 0.8037310271486259 and parameters: {'n_estimators': 148, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:15:57,254] Trial 40 finished with value: 0.8019826711702619 and parameters: {'n_estimators': 187, 'max_depth': 32, 'min_samples_split': 5}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:20:18,300] Trial 41 finished with value: 0.8043779313413645 and parameters: {'n_estimators': 198, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:24:40,805] Trial 42 finished with value: 0.8038533952946789 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 3}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:28:50,398] Trial 43 finished with value: 0.8043079731494722 and parameters: {'n_estimators': 190, 'max_depth': 28, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:29:05,948] Trial 44 finished with value: 0.7607216793465431 and parameters: {'n_estimators': 12, 'max_depth': 31, 'min_samples_split': 3}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:33:12,332] Trial 45 finished with value: 0.8036261283759415 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:34:52,873] Trial 46 finished with value: 0.7920695785058371 and parameters: {'n_estimators': 78, 'max_depth': 28, 'min_samples_split': 12}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:35:21,227] Trial 47 finished with value: 0.7597950936957689 and parameters: {'n_estimators': 27, 'max_depth': 14, 'min_samples_split': 8}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:39:05,827] Trial 48 finished with value: 0.8017553804088102 and parameters: {'n_estimators': 173, 'max_depth': 31, 'min_samples_split': 5}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:43:24,652] Trial 49 finished with value: 0.8034862715989429 and parameters: {'n_estimators': 192, 'max_depth': 26, 'min_samples_split': 4}. Best is trial 35 with value: 0.8052171123525645.\n",
            "[I 2024-06-12 01:43:24,655] A new study created in memory with name: no-name-a14d143c-dda6-43d3-8f9d-e3d805b43efd\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for Random Forest (Acoustic Indices): {'n_estimators': 199, 'max_depth': 31, 'min_samples_split': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-12 01:48:02,175] Trial 0 finished with value: 0.7574522425617999 and parameters: {'n_estimators': 195, 'max_depth': 12, 'min_samples_split': 14}. Best is trial 0 with value: 0.7574522425617999.\n",
            "[I 2024-06-12 01:50:40,954] Trial 1 finished with value: 0.7889923928627862 and parameters: {'n_estimators': 76, 'max_depth': 28, 'min_samples_split': 3}. Best is trial 1 with value: 0.7889923928627862.\n",
            "[I 2024-06-12 01:51:10,799] Trial 2 finished with value: 0.5896288264358333 and parameters: {'n_estimators': 94, 'max_depth': 2, 'min_samples_split': 15}. Best is trial 1 with value: 0.7889923928627862.\n",
            "[I 2024-06-12 01:52:49,840] Trial 3 finished with value: 0.7768938485769573 and parameters: {'n_estimators': 50, 'max_depth': 25, 'min_samples_split': 16}. Best is trial 1 with value: 0.7889923928627862.\n",
            "[I 2024-06-12 01:55:58,691] Trial 4 finished with value: 0.7865272469449619 and parameters: {'n_estimators': 106, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 1 with value: 0.7889923928627862.\n",
            "[I 2024-06-12 01:56:14,805] Trial 5 finished with value: 0.7361399564395444 and parameters: {'n_estimators': 13, 'max_depth': 11, 'min_samples_split': 5}. Best is trial 1 with value: 0.7889923928627862.\n",
            "[I 2024-06-12 01:59:47,431] Trial 6 finished with value: 0.7890972632076189 and parameters: {'n_estimators': 119, 'max_depth': 25, 'min_samples_split': 7}. Best is trial 6 with value: 0.7890972632076189.\n",
            "[I 2024-06-12 02:00:49,651] Trial 7 finished with value: 0.7744986104145141 and parameters: {'n_estimators': 38, 'max_depth': 18, 'min_samples_split': 15}. Best is trial 6 with value: 0.7890972632076189.\n",
            "[I 2024-06-12 02:01:23,358] Trial 8 finished with value: 0.768711631513198 and parameters: {'n_estimators': 21, 'max_depth': 17, 'min_samples_split': 6}. Best is trial 6 with value: 0.7890972632076189.\n",
            "[I 2024-06-12 02:04:11,315] Trial 9 finished with value: 0.7801632606019586 and parameters: {'n_estimators': 101, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 6 with value: 0.7890972632076189.\n",
            "[I 2024-06-12 02:08:54,297] Trial 10 finished with value: 0.785740464883593 and parameters: {'n_estimators': 156, 'max_depth': 32, 'min_samples_split': 11}. Best is trial 6 with value: 0.7890972632076189.\n",
            "[I 2024-06-12 02:12:57,309] Trial 11 finished with value: 0.7933982449396337 and parameters: {'n_estimators': 133, 'max_depth': 31, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:17:18,449] Trial 12 finished with value: 0.7926639150156894 and parameters: {'n_estimators': 143, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:21:47,768] Trial 13 finished with value: 0.7929436634167305 and parameters: {'n_estimators': 146, 'max_depth': 31, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:26:52,160] Trial 14 finished with value: 0.7913701515645585 and parameters: {'n_estimators': 168, 'max_depth': 27, 'min_samples_split': 4}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:30:51,986] Trial 15 finished with value: 0.7870692221031096 and parameters: {'n_estimators': 134, 'max_depth': 29, 'min_samples_split': 10}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:36:20,285] Trial 16 finished with value: 0.7933982284331392 and parameters: {'n_estimators': 185, 'max_depth': 22, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:42:07,481] Trial 17 finished with value: 0.7904085483026844 and parameters: {'n_estimators': 196, 'max_depth': 23, 'min_samples_split': 8}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:46:13,380] Trial 18 finished with value: 0.7671206255279155 and parameters: {'n_estimators': 172, 'max_depth': 13, 'min_samples_split': 4}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:48:34,627] Trial 19 finished with value: 0.6673426571368072 and parameters: {'n_estimators': 178, 'max_depth': 6, 'min_samples_split': 12}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:52:36,212] Trial 20 finished with value: 0.7901987232464914 and parameters: {'n_estimators': 125, 'max_depth': 23, 'min_samples_split': 5}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 02:57:28,196] Trial 21 finished with value: 0.7931184937875102 and parameters: {'n_estimators': 151, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:02:23,750] Trial 22 finished with value: 0.7933632630926053 and parameters: {'n_estimators': 156, 'max_depth': 29, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:07:57,836] Trial 23 finished with value: 0.7905659047149581 and parameters: {'n_estimators': 183, 'max_depth': 26, 'min_samples_split': 4}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:12:51,784] Trial 24 finished with value: 0.791649869703693 and parameters: {'n_estimators': 163, 'max_depth': 24, 'min_samples_split': 3}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:16:41,436] Trial 25 finished with value: 0.7908980795766546 and parameters: {'n_estimators': 130, 'max_depth': 21, 'min_samples_split': 3}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:19:04,550] Trial 26 finished with value: 0.7876286822240927 and parameters: {'n_estimators': 79, 'max_depth': 29, 'min_samples_split': 5}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:24:04,140] Trial 27 finished with value: 0.7831878611386013 and parameters: {'n_estimators': 188, 'max_depth': 16, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:27:31,207] Trial 28 finished with value: 0.7867370087262593 and parameters: {'n_estimators': 118, 'max_depth': 22, 'min_samples_split': 9}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:32:19,705] Trial 29 finished with value: 0.7905309549638911 and parameters: {'n_estimators': 160, 'max_depth': 27, 'min_samples_split': 6}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:37:13,260] Trial 30 finished with value: 0.7755126676478676 and parameters: {'n_estimators': 198, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:41:46,547] Trial 31 finished with value: 0.7933807517235509 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:46:02,303] Trial 32 finished with value: 0.7923492113614166 and parameters: {'n_estimators': 140, 'max_depth': 29, 'min_samples_split': 3}. Best is trial 11 with value: 0.7933982449396337.\n",
            "[I 2024-06-12 03:51:22,309] Trial 33 finished with value: 0.7947794423752178 and parameters: {'n_estimators': 175, 'max_depth': 28, 'min_samples_split': 2}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 03:57:04,696] Trial 34 finished with value: 0.7924716024331563 and parameters: {'n_estimators': 184, 'max_depth': 27, 'min_samples_split': 4}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:02:39,846] Trial 35 finished with value: 0.7936604716967403 and parameters: {'n_estimators': 172, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:08:31,222] Trial 36 finished with value: 0.7927338539500046 and parameters: {'n_estimators': 173, 'max_depth': 32, 'min_samples_split': 3}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:14:46,380] Trial 37 finished with value: 0.785111063077212 and parameters: {'n_estimators': 200, 'max_depth': 26, 'min_samples_split': 13}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:18:22,317] Trial 38 finished with value: 0.7208594185237001 and parameters: {'n_estimators': 188, 'max_depth': 9, 'min_samples_split': 6}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:20:41,716] Trial 39 finished with value: 0.7876286629665158 and parameters: {'n_estimators': 72, 'max_depth': 24, 'min_samples_split': 5}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:21:33,743] Trial 40 finished with value: 0.5896288264358333 and parameters: {'n_estimators': 167, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:25:29,392] Trial 41 finished with value: 0.7924016644158686 and parameters: {'n_estimators': 118, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:30:26,483] Trial 42 finished with value: 0.7929961109690177 and parameters: {'n_estimators': 150, 'max_depth': 31, 'min_samples_split': 2}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:36:13,360] Trial 43 finished with value: 0.7929086870718668 and parameters: {'n_estimators': 175, 'max_depth': 28, 'min_samples_split': 3}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:40:45,267] Trial 44 finished with value: 0.7927513508341976 and parameters: {'n_estimators': 139, 'max_depth': 31, 'min_samples_split': 2}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:45:44,742] Trial 45 finished with value: 0.7917023310113923 and parameters: {'n_estimators': 159, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:49:10,298] Trial 46 finished with value: 0.7906883031229178 and parameters: {'n_estimators': 106, 'max_depth': 25, 'min_samples_split': 4}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 04:55:20,463] Trial 47 finished with value: 0.7896917005904932 and parameters: {'n_estimators': 189, 'max_depth': 32, 'min_samples_split': 7}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 05:00:00,208] Trial 48 finished with value: 0.782890679128263 and parameters: {'n_estimators': 150, 'max_depth': 28, 'min_samples_split': 16}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 05:05:26,335] Trial 49 finished with value: 0.7915449571755965 and parameters: {'n_estimators': 178, 'max_depth': 30, 'min_samples_split': 5}. Best is trial 33 with value: 0.7947794423752178.\n",
            "[I 2024-06-12 05:05:26,338] A new study created in memory with name: no-name-377c39ae-796e-4787-9cde-a0326b972e2d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Random Forest (VGGish): {'n_estimators': 175, 'max_depth': 28, 'min_samples_split': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-12 05:06:40,412] Trial 0 finished with value: 0.6506635156869058 and parameters: {'n_estimators': 74, 'max_depth': 7, 'min_samples_split': 12}. Best is trial 0 with value: 0.6506635156869058.\n",
            "[I 2024-06-12 05:08:56,261] Trial 1 finished with value: 0.6338968953182053 and parameters: {'n_estimators': 156, 'max_depth': 6, 'min_samples_split': 16}. Best is trial 0 with value: 0.6506635156869058.\n",
            "[I 2024-06-12 05:10:05,350] Trial 2 finished with value: 0.6689162130062978 and parameters: {'n_estimators': 63, 'max_depth': 8, 'min_samples_split': 3}. Best is trial 2 with value: 0.6689162130062978.\n",
            "[I 2024-06-12 05:12:36,412] Trial 3 finished with value: 0.6690385930737079 and parameters: {'n_estimators': 137, 'max_depth': 8, 'min_samples_split': 4}. Best is trial 3 with value: 0.6690385930737079.\n",
            "[I 2024-06-12 05:13:52,363] Trial 4 finished with value: 0.6147874870904312 and parameters: {'n_estimators': 126, 'max_depth': 4, 'min_samples_split': 14}. Best is trial 3 with value: 0.6690385930737079.\n",
            "[I 2024-06-12 05:16:45,327] Trial 5 finished with value: 0.7461404812543674 and parameters: {'n_estimators': 95, 'max_depth': 16, 'min_samples_split': 12}. Best is trial 5 with value: 0.7461404812543674.\n",
            "[I 2024-06-12 05:17:02,229] Trial 6 finished with value: 0.6505761321389637 and parameters: {'n_estimators': 16, 'max_depth': 7, 'min_samples_split': 14}. Best is trial 5 with value: 0.7461404812543674.\n",
            "[I 2024-06-12 05:23:12,267] Trial 7 finished with value: 0.7554766352541656 and parameters: {'n_estimators': 192, 'max_depth': 18, 'min_samples_split': 11}. Best is trial 7 with value: 0.7554766352541656.\n",
            "[I 2024-06-12 05:23:55,011] Trial 8 finished with value: 0.5994195307796008 and parameters: {'n_estimators': 123, 'max_depth': 2, 'min_samples_split': 10}. Best is trial 7 with value: 0.7554766352541656.\n",
            "[I 2024-06-12 05:25:36,108] Trial 9 finished with value: 0.7535185385861364 and parameters: {'n_estimators': 51, 'max_depth': 20, 'min_samples_split': 9}. Best is trial 7 with value: 0.7554766352541656.\n",
            "[I 2024-06-12 05:32:48,021] Trial 10 finished with value: 0.7660541289955219 and parameters: {'n_estimators': 200, 'max_depth': 31, 'min_samples_split': 7}. Best is trial 10 with value: 0.7660541289955219.\n",
            "[I 2024-06-12 05:39:40,797] Trial 11 finished with value: 0.7659842056506738 and parameters: {'n_estimators': 192, 'max_depth': 30, 'min_samples_split': 7}. Best is trial 10 with value: 0.7660541289955219.\n",
            "[I 2024-06-12 05:46:33,088] Trial 12 finished with value: 0.7658792802841927 and parameters: {'n_estimators': 197, 'max_depth': 31, 'min_samples_split': 7}. Best is trial 10 with value: 0.7660541289955219.\n",
            "[I 2024-06-12 05:52:15,080] Trial 13 finished with value: 0.7657044636688249 and parameters: {'n_estimators': 164, 'max_depth': 32, 'min_samples_split': 6}. Best is trial 10 with value: 0.7660541289955219.\n",
            "[I 2024-06-12 05:57:48,925] Trial 14 finished with value: 0.7630469730725061 and parameters: {'n_estimators': 167, 'max_depth': 26, 'min_samples_split': 7}. Best is trial 10 with value: 0.7660541289955219.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "<"
      ],
      "metadata": {
        "id": "QoRQheF_KEze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **K-nn + Optuna**"
      ],
      "metadata": {
        "id": "dkRai8xmNTwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_knn(trial, X_train, y_train):\n",
        "    n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n",
        "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
        "\n",
        "    clf = KNeighborsClassifier(\n",
        "        n_neighbors=n_neighbors,\n",
        "        weights=weights\n",
        "    )\n",
        "\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=3)\n",
        "    return scores.mean()\n",
        "\n",
        "# Crear y optimizar estudio con Optuna para cada conjunto de datos\n",
        "best_params_rf = {}\n",
        "for dataset_name, (X_train, y_train) in datasets.items():\n",
        "    study_knn = optuna.create_study(direction='maximize')\n",
        "    study_knn.optimize(lambda trial: objective_knn(trial, X_train, y_train), n_trials=50)\n",
        "    best_params_rf[dataset_name] = study_knn.best_params\n",
        "    print(f'Best parameters for K-NN ({dataset_name}): {study_knn.best_params}')"
      ],
      "metadata": {
        "id": "xWTd5iJlNMNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM + Optuna**"
      ],
      "metadata": {
        "id": "xDHcEDBpNo1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_svm(trial, X_train, y_train):\n",
        "    C = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "\n",
        "    clf = SVC(\n",
        "        C=C,\n",
        "        kernel=kernel,\n",
        "        gamma='auto'\n",
        "    )\n",
        "\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=3)\n",
        "    return scores.mean()\n",
        "\n",
        "# Crear y optimizar estudio con Optuna para cada conjunto de datos\n",
        "best_params_rf = {}\n",
        "for dataset_name, (X_train, y_train) in datasets.items():\n",
        "    study_svm = optuna.create_study(direction='maximize')\n",
        "    study_svm.optimize(lambda trial: objective_svm(trial, X_train, y_train), n_trials=50)\n",
        "    best_params_rf[dataset_name] = study_svm.best_params\n",
        "    print(f'Best parameters for SVM ({dataset_name}): {study_svm.best_params}')"
      ],
      "metadata": {
        "id": "WHXT0Y4_NoSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XGBoost + Optuna**"
      ],
      "metadata": {
        "id": "z-pBMMS5Nvv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def objective_xgb(trial, X_train, y_train):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.2)\n",
        "\n",
        "    clf = xgb.XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=3)\n",
        "    return scores.mean()\n",
        "\n",
        "# Crear y optimizar estudio con Optuna para cada conjunto de datos\n",
        "best_params_rf = {}\n",
        "for dataset_name, (X_train, y_train) in datasets.items():\n",
        "    study_xgb = optuna.create_study(direction='minimize')\n",
        "    study_xgb.optimize(lambda trial: objective_xgb(trial, X_train, y_train), n_trials=50)\n",
        "    best_params_rf[dataset_name] = study_xgb.best_params\n",
        "    print(f'Best parameters for XGBoost ({dataset_name}): {study_xgb.best_params}')"
      ],
      "metadata": {
        "id": "7yQ6XOzJNsYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar y evaluar los mejores modelos\n",
        "results = {}\n",
        "for ds_name, (X, y) in datasets.items():\n",
        "    X_train, X_test, y_train, y_test = generate_and_split_data((X, y))\n",
        "\n",
        "    # Random Forest\n",
        "    best_rf = RandomForestClassifier(**best_params_rf[ds_name], random_state=42)\n",
        "    best_rf.fit(X_train, y_train)\n",
        "    accuracy_rf = best_rf.score(X_test, y_test)\n",
        "    results[(ds_name, 'RandomForest')] = (best_rf, accuracy_rf)\n",
        "\n",
        "    # K-Neighbors\n",
        "    best_knn = KNeighborsClassifier(**best_params_knn[ds_name])\n",
        "    best_knn.fit(X_train, y_train)\n",
        "    accuracy_knn = best_knn.score(X_test, y_test)\n",
        "    results[(ds_name, 'K-nn')] = (best_knn, accuracy_knn)\n",
        "\n",
        "    # SVC\n",
        "    best_svc = SVC(**best_params_svm[ds_name], random_state=42)\n",
        "    best_svc.fit(X_train, y_train)\n",
        "    accuracy_svc = best_svc.score(X_test, y_test)\n",
        "    results[(ds_name, 'SVM')] = (best_svc, accuracy_svc)\n",
        "\n",
        "    # XGBoost\n",
        "    best_xgb = xgb.XGBClassifier(**best_params_xgb[ds_name], random_state=42)\n",
        "    best_xgb.fit(X_train, y_train)\n",
        "    accuracy_xgb = best_xgb.score(X_test, y_test)\n",
        "    results[(ds_name, 'XGBoost')] = (best_xgb, accuracy_xgb)"
      ],
      "metadata": {
        "id": "cgisDiJtOHs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para realizar la optimización y entrenar los modelos\n",
        "def optimize_and_train(dataset_name, X_train, y_train):\n",
        "    best_rf = RandomForestClassifier(**study_rf.best_params)\n",
        "    best_rf.fit(X_train, y_train)\n",
        "\n",
        "    best_knn = KNeighborsClassifier(**study_knn.best_params)\n",
        "    best_knn.fit(X_train, y_train)\n",
        "\n",
        "    best_svm = SVC(**study_svm.best_params)\n",
        "    best_svm.fit(X_train, y_train)\n",
        "\n",
        "    best_xgb = xgb.XGBClassifier(**study_xgb.best_params)\n",
        "    best_xgb.fit(X_train, y_train)\n",
        "\n",
        "    return {\n",
        "        'Random Forest': best_rf,\n",
        "        'K-NN': best_knn,\n",
        "        'SVM': best_svm,\n",
        "        'XGBoost': best_xgb\n",
        "    }\n",
        "\n",
        "# Optimizar y entrenar modelos para cada conjunto de datos\n",
        "models = {}\n",
        "for dataset_name, (X_train, y_train) in datasets.items():\n",
        "    models[dataset_name] = optimize_and_train(dataset_name, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCYk8zm6N0Qz",
        "outputId": "3a58160f-ea5f-41d2-aed7-c684ad61cf17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-11 13:49:01,675] A new study created in memory with name: no-name-8eff2935-ff3e-4163-8dda-4391938b8a6f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing Acoustic Indices...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:51:40,726] Trial 0 finished with value: 0.7963179558738668 and parameters: {'n_estimators': 127, 'max_depth': 25, 'min_samples_split': 8}. Best is trial 0 with value: 0.7963179558738668.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:52:38,001] Trial 1 finished with value: 0.6432330163050145 and parameters: {'n_estimators': 124, 'max_depth': 6, 'min_samples_split': 12}. Best is trial 0 with value: 0.7963179558738668.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:55:24,544] Trial 2 finished with value: 0.7852160049501876 and parameters: {'n_estimators': 170, 'max_depth': 17, 'min_samples_split': 11}. Best is trial 0 with value: 0.7963179558738668.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:56:12,754] Trial 3 finished with value: 0.6796160730596522 and parameters: {'n_estimators': 81, 'max_depth': 8, 'min_samples_split': 12}. Best is trial 0 with value: 0.7963179558738668.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:56:47,916] Trial 4 finished with value: 0.7875412922569583 and parameters: {'n_estimators': 32, 'max_depth': 32, 'min_samples_split': 6}. Best is trial 0 with value: 0.7963179558738668.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:57:48,856] Trial 5 finished with value: 0.6996171364447102 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 0 with value: 0.7963179558738668.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 13:59:56,843] Trial 6 finished with value: 0.7991327790397452 and parameters: {'n_estimators': 115, 'max_depth': 31, 'min_samples_split': 6}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:00:55,894] Trial 7 finished with value: 0.7456685348992275 and parameters: {'n_estimators': 74, 'max_depth': 12, 'min_samples_split': 15}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:03:01,692] Trial 8 finished with value: 0.7899714875066882 and parameters: {'n_estimators': 116, 'max_depth': 28, 'min_samples_split': 14}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:05:19,754] Trial 9 finished with value: 0.7894470009794862 and parameters: {'n_estimators': 131, 'max_depth': 20, 'min_samples_split': 12}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:05:54,036] Trial 10 finished with value: 0.6068150208036394 and parameters: {'n_estimators': 197, 'max_depth': 2, 'min_samples_split': 3}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:08:41,369] Trial 11 finished with value: 0.7976816830190548 and parameters: {'n_estimators': 154, 'max_depth': 26, 'min_samples_split': 8}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:11:45,064] Trial 12 finished with value: 0.7982411559784226 and parameters: {'n_estimators': 163, 'max_depth': 32, 'min_samples_split': 8}. Best is trial 6 with value: 0.7991327790397452.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:14:50,099] Trial 13 finished with value: 0.8019476443888873 and parameters: {'n_estimators': 166, 'max_depth': 32, 'min_samples_split': 2}. Best is trial 13 with value: 0.8019476443888873.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:15:48,397] Trial 14 finished with value: 0.7938353589232233 and parameters: {'n_estimators': 54, 'max_depth': 22, 'min_samples_split': 2}. Best is trial 13 with value: 0.8019476443888873.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:19:29,984] Trial 15 finished with value: 0.8029442368340097 and parameters: {'n_estimators': 198, 'max_depth': 30, 'min_samples_split': 4}. Best is trial 15 with value: 0.8029442368340097.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:22:35,465] Trial 16 finished with value: 0.7803905632847674 and parameters: {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 15 with value: 0.8029442368340097.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:26:01,710] Trial 17 finished with value: 0.8049722770214914 and parameters: {'n_estimators': 184, 'max_depth': 27, 'min_samples_split': 2}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:29:20,194] Trial 18 finished with value: 0.7994475102048422 and parameters: {'n_estimators': 182, 'max_depth': 22, 'min_samples_split': 4}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:32:02,350] Trial 19 finished with value: 0.799534924014691 and parameters: {'n_estimators': 147, 'max_depth': 28, 'min_samples_split': 6}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:35:28,144] Trial 20 finished with value: 0.8011958735194259 and parameters: {'n_estimators': 184, 'max_depth': 25, 'min_samples_split': 4}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:38:55,127] Trial 21 finished with value: 0.8041680145824243 and parameters: {'n_estimators': 184, 'max_depth': 28, 'min_samples_split': 2}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:42:17,654] Trial 22 finished with value: 0.8041155505236425 and parameters: {'n_estimators': 182, 'max_depth': 28, 'min_samples_split': 2}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:45:01,089] Trial 23 finished with value: 0.8028392692842647 and parameters: {'n_estimators': 146, 'max_depth': 28, 'min_samples_split': 2}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:48:10,896] Trial 24 finished with value: 0.8003916110803586 and parameters: {'n_estimators': 177, 'max_depth': 22, 'min_samples_split': 2}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:50:43,488] Trial 25 finished with value: 0.7970697698436194 and parameters: {'n_estimators': 145, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[I 2024-06-11 14:50:55,746] Trial 26 finished with value: 0.7613685798711719 and parameters: {'n_estimators': 11, 'max_depth': 26, 'min_samples_split': 5}. Best is trial 17 with value: 0.8049722770214914.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluar y Graficar los Resultados**"
      ],
      "metadata": {
        "id": "-R0qQ_7kO9MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def evaluate_models(models, X_val, y_val):\n",
        "    for model_name, model in models.items():\n",
        "        y_pred = model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        print(f'Accuracy for {model_name}: {accuracy}')\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "        disp.plot()\n",
        "        plt.title(f'Confusion Matrix for {model_name}')\n",
        "        plt.show()\n",
        "\n",
        "# Evaluar los modelos en el conjunto de validación\n",
        "for dataset_name, (X_val, y_val) in {\n",
        "    'Acoustic Indices': (X_ai_val, y_val),\n",
        "    'VGGish': (X_vgg_val, y_val),\n",
        "    'YAMNet': (X_yamn_val, y_val),\n",
        "    'PANNs': (X_panns_val, y_val)\n",
        "}.items():\n",
        "    print(f\"Evaluating models for {dataset_name}...\")\n",
        "    evaluate_models(models[dataset_name], X_val, y_val)"
      ],
      "metadata": {
        "id": "JfXrYsoVOIgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVqGXuYCPCGd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}